<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="..\estilo.css">
    <title>UTP-IA   </title>
</head>
<body>
    <header>
        <h1>UTP-IA</h1>
    </header>
    
    <nav>
        <ul>
            <li><a href="..\index.html">Inicio</a></li>
            <li><a href="..\src\historia.html">Historia</a></li>
            <li><a href="..\src\acercade.html">Acerca de</a></li>
            <li><a href="..\src\etica.html">Etica</a></li>
            <li><a href="..\src\investigacion.html">Investigación</a></li>
        </ul>
    </nav>
    <hr>
    
    <main>
        <div class="info">
            <h1>Ética en la inteligencia Artificial</h1>
            <br>
            <p>

                La UNESCO ha planteado diez principios básicos para establecer un enfoque ético de las inteligencias artificiales:
                <br><br>
                - Proporcionalidad e Inocuidad: El uso de sistemas de IA no debe ir más allá de lo necesario para alcanzar un objetivo legítimo. La evaluación de riesgos debe utilizarse para prevenir los daños que puedan derivarse de usos ilegítimos.
                <br>
                - Seguridad y Protección: Los daños no deseados (riesgos de seguridad) y las vulnerabilidades a los ataques (riesgos de protección) deberían ser evitados y tomados en consideración.
                <br>
                - Derecho a la intimidad y protección de datos: La privacidad debe protegerse y promoverse a lo largo de todo el ciclo de vida de la IA. También deben establecerse marcos adecuados de protección de datos.
                <br>
                - Gobernanza y colaboración adaptativas de múltiples partes interesadas: En el uso de datos, deben respetarse el derecho internacional y la soberanía nacional. La participación de diversas partes interesadas a lo largo del ciclo de vida de los sistemas de IA es necesaria para el desarrollo de enfoques inclusivos de gobernanza.
                <br>
                - Responsabilidad y rendición de cuentas: Los sistemas de IA deben ser auditables y trazables. Deben existir mecanismos de supervisión, evaluación de impacto, auditoría y diligencia debida para evitar conflictos con las normas de derechos humanos y amenazas al bienestar medioambiental.
                <br>
                - Transparencia y explicabilidad: El despliegue ético de los sistemas de IA depende de su transparencia y explicabilidad (T&E). El nivel de T&E debe ser adecuado al contexto, ya que puede haber tensiones entre T&E y otros principios como la privacidad, la seguridad y la protección.
                <br>
                - Supervisión y decisión humanas: Los Estados Miembros deberían velar por que siempre sea posible atribuir la responsabilidad ética y jurídica a personas físicas o a entidades jurídicas existentes.
                <br>
                - Sostenibilidad: Las tecnologías de IA deben evaluarse en función de su impacto en la "sostenibilidad", entendida como un conjunto de objetivos en constante evolución, incluidos los establecidos en los Objetivos de Desarrollo Sostenible (ODS) de Naciones Unidas.
                <br>
                - Sensibilización y educación: La sensibilización y la comprensión del público respecto de la IA y el valor de los datos deberían promoverse mediante una educación abierta y accesible, la participación cívica, las competencias digitales y la capacitación, y la alfabetización mediática e información.
                <br>
                - Equidad y no discriminación: Los actores de la IA deberían promover la justicia social, salvaguardar la equidad y luchar contra todo tipo de discriminación, adoptando un enfoque inclusivo para garantizar que los beneficios de la IA sean accesibles para todos.
            </p>

        </div>
    </main>
    
    <footer>
        <p>Derechos de autor &copy; 2023 Mi Blog</p>
    </footer>
</body>
</html>
